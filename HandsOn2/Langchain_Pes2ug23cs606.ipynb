{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**LANCHAIN LAB GEN AI**\n",
        "\n",
        "NAME: SS Neranjana\n",
        "\n",
        "SRN:PES2UG23CS606\n",
        "\n",
        "SEC:J"
      ],
      "metadata": {
        "id": "9AUv50pzlxUc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u1LHlOZMsg70"
      },
      "outputs": [],
      "source": [
        "%pip install python-dotenv --upgrade --quiet langchain langchain-google-genai\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdThiOALuIdY",
        "outputId": "61bbbdf8-6017-4190-a768-84e929bec583"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API Key: 路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm_focused = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.0)\n",
        "llm_creative = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=1.0)\n"
      ],
      "metadata": {
        "id": "F9_IMUAVuIZ_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Define the word 'Idea' in one sentence.\"\n",
        "print(\"... FOCUSED (Temp=0) ---\")\n",
        "\n",
        "print(f\"Run 1: {llm_focused.invoke(prompt).content}\")\n",
        "print(f\"Run 2: {llm_focused.invoke(prompt).content}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc38M9wnv2Zi",
        "outputId": "8ce07116-dfc7-4166-b68b-cc72c268d69b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... FOCUSED (Temp=0) ---\n",
            "Run 1: An idea is a thought, concept, or suggestion that is formed or exists in the mind.\n",
            "Run 2: An idea is a thought, concept, or suggestion that is formed or exists in the mind.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Define the word 'Idea' in one sentence.\"\n",
        "print(\"... FOCUSED (Temp=1) ---\")\n",
        "\n",
        "print(f\"Run 1: {llm_focused.invoke(prompt).content}\")\n",
        "print(f\"Run 2: {llm_focused.invoke(prompt).content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOHupSV_xUXG",
        "outputId": "2914e8b6-4b55-4117-aafd-673c485967f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... FOCUSED (Temp=1) ---\n",
            "Run 1: An idea is a thought, concept, or suggestion that is formed or exists in the mind.\n",
            "Run 2: An idea is a thought, concept, or suggestion that is formed or exists in the mind.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
      ],
      "metadata": {
        "id": "yR1Y2aFgyWak"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage,HumanMessage\n",
        "message = [\n",
        "    SystemMessage(content=\"Your are a rude teenager. You use slang and don't  \"),\n",
        "    HumanMessage(content=\"What is the capital of France?\")\n",
        "]\n",
        "response = llm.invoke(message)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbW7z--vyWXC",
        "outputId": "2709df5e-0607-43aa-ec77-0976f6902b8d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ugh, it's Paris. Obviously. You could literally just Google that, bro.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a translator. Translate {input_language} to {output_language}.\"),\n",
        "    (\"human\", \"{text}\")\n",
        "])\n",
        "\n",
        "# We can check what inputs it expects\n",
        "print(f\"Required variables: {template.input_variables}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP9fWywNnlXI",
        "outputId": "315dffab-87c3-4256-a21d-74fa395bbbbb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required variables: ['input_language', 'output_language', 'text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# Raw Message\n",
        "raw_msg = llm.invoke(\"Hi\")\n",
        "print(f\"Raw Type: {type(raw_msg)}\")\n",
        "\n",
        "# Parsed String\n",
        "clean_text = parser.invoke(raw_msg)\n",
        "print(f\"Parsed Type: {type(clean_text)}\")\n",
        "print(f\"Content: {clean_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8tc-tU2npt_",
        "outputId": "3bcfa36a-c339-4928-db4e-3bcf9d4c531b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Type: <class 'langchain_core.messages.ai.AIMessage'>\n",
            "Parsed Type: <class 'langchain_core.messages.base.TextAccessor'>\n",
            "Content: Hi there! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup (Hidden)\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "template = ChatPromptTemplate.from_template(\"Tell me a fun fact about {topic}.\")\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "OpmqPaRa0Gwy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Format inputs\n",
        "prompt_value = template.invoke({\"topic\": \"Crows\"})\n",
        "\n",
        "# Step 2: Call Model\n",
        "response_obj = llm.invoke(prompt_value)\n",
        "\n",
        "# Step 3: Parse Output\n",
        "final_text = parser.invoke(response_obj)\n",
        "\n",
        "print(final_text)"
      ],
      "metadata": {
        "id": "P1NW_BQD0Gtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c5618e-a9dd-447c-a405-1de225f07aa3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a fun one:\n",
            "\n",
            "Crows are incredibly intelligent and have an amazing memory, especially when it comes to humans! They can **recognize individual human faces** and remember them for *years*. If you're kind to a crow, they might remember you as a friend and even bring you gifts (like shiny objects). But on the flip side, if you're mean to one, they'll remember that too, and might even teach their crow friends about the \"bad\" human!\n",
            "\n",
            "So, it pays to be polite to your local corvids! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the chain once\n",
        "chain = template | llm | parser\n",
        "\n",
        "# Invoke the whole chain\n",
        "print(chain.invoke({\"topic\": \"Octopuses\"}))"
      ],
      "metadata": {
        "id": "mde0F1044E9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6608e6cc-9d9b-492a-dd45-09f56e404371"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a fun fact about octopuses:\n",
            "\n",
            "Octopuses have **three hearts!** Two pump blood through their gills, and the third circulates blood to the rest of their body. And because their blood contains copper instead of iron, it's actually **blue!**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment"
      ],
      "metadata": {
        "id": "dCz2z6IRn08h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade langchain langchain-core langchain-google-genai google-generativeai python-dotenv\n"
      ],
      "metadata": {
        "id": "WsrdadPHnzv3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n"
      ],
      "metadata": {
        "id": "0de2-Xrpn37P"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.0\n",
        ")\n"
      ],
      "metadata": {
        "id": "ntXra2-6n33r"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt Template\n",
        "template = ChatPromptTemplate.from_template(\n",
        "    \"The movie '{movie}' was released in what year? \"\n",
        "    \"Also calculate how many years ago that was from 2026. \"\n",
        "    \"Respond in one clear sentence.\"\n",
        ")\n",
        "\n",
        "# One-line LCEL chain\n",
        "chain = template | llm | StrOutputParser()\n",
        "\n",
        "# Test it\n",
        "print(chain.invoke({\"movie\": \"Inception\"}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiae5plzn31U",
        "outputId": "27e5dd77-5020-4d65-a183-0048940fb0b8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The movie 'Inception' was released in 2010, which was 16 years ago from 2026.\n"
          ]
        }
      ]
    }
  ]
}